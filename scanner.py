import requests
from bs4 import BeautifulSoup
import subprocess
import validators
import bleach
import os
import logging
from fpdf import FPDF

FLAGS = {
    "Unknown": "üåê",
    "AD": "üá¶üá©",
    "AE": "üá¶üá™",
    "AF": "üá¶üá´",
    "TN": "üáπüá≥",
}

logging.basicConfig(filename='scan.log', level=logging.INFO)

def is_valid_url(url):
    return validators.url(url)

def get_ip_info(url):
    try:
        ip_info = requests.get(f'https://ipinfo.io/{url}/json').json()
        return {
            "IP": ip_info['ip'],
            "City": ip_info['city'],
            "Region": ip_info['region'],
            "Country": ip_info['country'],
            "Flag": ip_info["country"]
        }
    except requests.exceptions.RequestException as e:
        logging.error("An error occurred while getting IP information: %s", str(e))
        return {
            "IP": "Unknown",
            "City": "Unknown",
            "Region": "Unknown",
            "Country": "Unknown",
            "Flag": "üåê"
        }

def scan_website(url):
    if not is_valid_url(url):
        logging.error("Invalid URL provided: %s", url)
        print("Invalid URL. Please provide a valid URL.")
        return []

    try:
        response = requests.get(url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            links = []
            for anchor in soup.find_all('a'):
                link = anchor.get('href')
                if link:
                    sanitized_link = bleach.clean(link, tags=[], attributes={})
                    links.append(sanitized_link)
            return links
        else:
            logging.error("Failed to retrieve URL: %s, Status code: %s", url, response.status_code)
            print(f"Failed to retrieve {url}. Status code: {response.status_code}")
    except requests.exceptions.RequestException as e:
        logging.error("An error occurred while scanning: %s", str(e))
        print(f"An error occurred: {e}")

def scan_for_malware(url):
    if not is_valid_url(url):
        logging.error("Invalid URL provided: %s", url)
        print("Invalid URL. Please provide a valid URL.")
        return

    try:
        response = requests.get(url)
        if response.status_code == 200:
            content = response.content
            with open('temp_file', 'wb') as temp_file:
                temp_file.write(content)
            result = subprocess.run(['clamscan', 'temp_file'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)
            if "Infected files: 0" in result.stdout:
                logging.info("No malware found on URL: %s", url)
                print(f"No malware found on {url}")
            else:
                logging.warning("Malware found on URL: %s:\n%s", url, result.stdout)
                print(f"Malware found on {url}:\n{result.stdout}")
        else:
            logging.error("Failed to retrieve URL: %s, Status code: %s", url, response.status_code)
            print(f"Failed to retrieve {url}. Status code: {response.status_code}")
    except requests.exceptions.RequestException as e:
        logging.error("An error occurred while scanning: %s", str(e))
        print(f"An error occurred: {e}")

def check_for_config_files(url):
    if not is_valid_url(url):
        logging.error("Invalid URL provided: %s", url)
        print("Invalid URL. Please provide a valid URL.")
        return []

    common_config_files = [
        "robots.txt",
        ".htaccess",
        "wp-config.php",
        "config.php",
        "web.config",
    ]

    found_config_files = []
    for file in common_config_files:
        config_url = f"{url}/{file}"
        response = requests.get(config_url)
        if response.status_code == 200:
            logging.info("Found a potentially sensitive configuration file: %s", config_url)
            print(f"Found a potentially sensitive configuration file: {config_url}")
            found_config_files.append(config_url)

    return found_config_files

def sql_injection_test(url):
    payload = {
        "username": "admin' OR '1'='1",
        "password": "password"
    }

    response = requests.post(url, data=payload)

    if "Login successful" in response.text:
        logging.warning("SQL injection test successful")
        print("SQL injection successful")
    else:
        logging.info("SQL injection test failed")
        print("SQL injection failed")

def create_pdf_report(website_url, links, malware_result, config_files_result, sql_injection_result, ip_info):
    class PDF(FPDF):
        def header(self):
            self.set_font('Arial', 'B', 12)
            self.cell(0, 10, 'Website Security Scan Report', align='C', ln=True)
            self.set_font('Arial', '', 10)
            self.cell(0, 10, f'Website URL: {website_url}', ln=True)

        def chapter_title(self, title):
            self.set_font('Arial', 'B', 12)
            self.cell(0, 10, title, ln=True)

        def chapter_body(self, body):
            self.set_font('Arial', '', 12)
            self.multi_cell(0, 10, body.encode('latin1', 'ignore').decode('latin1'))

        def chapter_table(self, headers, data):
            self.set_font('Arial', 'B', 12)
            for header in headers:
                self.cell(40, 10, header, 1)
            self.ln()
            self.set_font('Arial', '', 12)
            for row in data:
                for col in row:
                    self.cell(40, 10, col, 1)
                self.ln()

    pdf = PDF()
    pdf.add_page()
    pdf.chapter_title('Links Found on the Website')
    for link in links:
        pdf.chapter_body(link)
    pdf.chapter_title('Malware Scan Result')
    pdf.chapter_body(malware_result)
    pdf.chapter_title('Potentially Sensitive Configuration Files')
    if config_files_result:
        for config_file in config_files_result:
            pdf.chapter_body(config_file)
    else:
        pdf.chapter_body("No potentially sensitive configuration files found.")

    pdf.chapter_title('IP Information')
    headers = ["IP", "City", "Region", "Country", "Flag"]
    data = [
        [ip_info["IP"], ip_info["City"], ip_info["Region"], ip_info["Country"], ip_info["Flag"]]
    ]
    pdf.chapter_table(headers, data)

    # Sanitize the website URL to create a valid filename
    filename = ''.join(c for c in website_url if c.isalnum() or c in ('-', '_', '.'))
    pdf_file_name = f"{filename}_report.pdf"

    pdf.output(pdf_file_name)
    return pdf_file_name

if __name__ == '__main__':
    website_url = input("Enter the website URL to scan: ")

    with open('temp_file', 'wb') as temp_file:
        temp_file.write(b"")
    os.chmod('temp_file', 0o600)

    links = scan_website(website_url)

    if links:
        print(f"Links found on {website_url}:\n")
        for link in links:
            print(link)

        print("\nScanning for malware...\n")
        scan_for_malware(website_url)

        print("\nChecking for common configuration files...\n")
        config_files_result = check_for_config_files(website_url)

        sql_injection_result = "SQL injection test result: No vulnerabilities found"

        print("\nPerforming SQL injection test...\n")

        ip_info = get_ip_info(website_url)

        print("\nGenerating PDF report...\n")

        pdf_file_name = create_pdf_report(website_url, links, "No malware found", config_files_result, sql_injection_result, ip_info)

        print(f"PDF report generated: {pdf_file_name}")

    else:
        print(f"No links found on {website_url}")

    os.remove('temp_file')
